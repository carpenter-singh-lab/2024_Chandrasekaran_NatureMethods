{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, both CellProfiler and DeepProfiler features of the plates are spherized and written to file. The whole plate normalized ORF, CRISPR and Compound profiles are read and the replicate plates are merged into a single dataframe. Then they are spherized and the output is written to file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "experiment_df = (\n",
    "    pd.read_csv('output/experiment-metadata.tsv', sep='\\t')\n",
    "    .query('Batch==\"2020_11_04_CPJUMP1\" or Batch==\"2020_11_04_CPJUMP1_DL\"')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "for batch in experiment_df.Batch.unique():\n",
    "    batch_df = experiment_df.query('Batch==@batch')\n",
    "    if batch == \"2020_11_04_CPJUMP1\":\n",
    "        filename = \"normalized.csv.gz\"\n",
    "    else:\n",
    "        filename = \"augmented.csv.gz\"\n",
    "    for cell in batch_df.Cell_type.unique():\n",
    "        cell_df = batch_df.query('Cell_type==@cell')\n",
    "        for perturbation in cell_df.Perturbation.unique():\n",
    "            perturbation_df = cell_df.query('Perturbation==@perturbation')\n",
    "            for timepoint in perturbation_df.Time.unique():\n",
    "                timepoint_df = perturbation_df.query('Time==@timepoint')\n",
    "                data_df = pd.DataFrame()\n",
    "                for plate in timepoint_df.Assay_Plate_Barcode.unique():\n",
    "                    plate_df = (\n",
    "                        utils.load_data(batch, plate, filename)\n",
    "                    )\n",
    "                    data_df = utils.concat_profiles(data_df, plate_df)\n",
    "\n",
    "                metadata_df = utils.get_metadata(data_df)\n",
    "                features_df = utils.get_featuredata(data_df).replace(np.inf, np.nan).dropna(axis=1, how=\"any\")\n",
    "                data_df = pd.concat([metadata_df, features_df], axis=1)\n",
    "\n",
    "                data_df = utils.sphere_plate_zca_corr(data_df)\n",
    "\n",
    "                for plate in timepoint_df.Assay_Plate_Barcode.unique():\n",
    "                    plate_df = data_df.query('Metadata_Plate==@plate')\n",
    "                    data_df.to_csv(f'../profiles/{batch}/{plate}/{plate}_spherized.csv.gz', index=False, float_format='%.5g')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}